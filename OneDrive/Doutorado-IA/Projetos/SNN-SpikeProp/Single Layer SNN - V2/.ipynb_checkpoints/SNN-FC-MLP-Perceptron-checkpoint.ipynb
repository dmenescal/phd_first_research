{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_mining import ImagePreProcessing\n",
    "from data_visualization import SpikeViz\n",
    "from spiking_neuron import Izhikevich\n",
    "\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_neurons = 10\n",
    "num_labels = 10\n",
    "num_patterns = 100\n",
    "\n",
    "ipp = ImagePreProcessing(dataset_patterns=x_train, \n",
    "                         dataset_labels=y_train,\n",
    "                         patch_size=5,\n",
    "                         patch_stride=1)\n",
    "ipp.setMaxPatterns(val=num_patterns)\n",
    "ipp.setMaxLabels(val=num_labels)\n",
    "\n",
    "patches_per_label = ipp.run()\n",
    "ipp.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição da camada de neurônios, pesos sinápticos e intensidade por patch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches_per_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.uniform(0, 1, (num_labels, num_patterns, num_neurons, ipp.patches_ds.shape[2], ipp.patch_size, ipp.patch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_per_neuron = np.zeros((num_labels, num_patterns, num_neurons))\n",
    "gama = 0.01\n",
    "\n",
    "for label in range(num_labels):\n",
    "    for pattern in range(num_patterns):\n",
    "        for neuron in range(num_neurons):\n",
    "            total_int = 0\n",
    "            for patch in range(ipp.patches_ds.shape[2]):\n",
    "                patch_int = 0\n",
    "                for i in range(ipp.patch_size):\n",
    "                    for j in range(ipp.patch_size):\n",
    "                        patch_int += patches_per_label[label][pattern][patch][i][j]*W[label][pattern][neuron][patch][i][j]\n",
    "                total_int += gama*patch_int\n",
    "                patch_int = 0\n",
    "            intensity_per_neuron[label][pattern][neuron] = total_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converter as intensidades em correntes ao longo do tempo. Nesse caso, as correntes são constantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 100 \n",
    "dt = 0.25\n",
    "timeline = np.arange(0, T+dt, dt)\n",
    "timeline.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currents_per_neuron = np.zeros((num_labels, num_patterns, num_neurons, timeline.shape[0]))\n",
    "for label in range(num_labels):\n",
    "    for pattern in range(num_patterns):\n",
    "        for neuron in range(num_neurons):\n",
    "            for time_step in range(timeline.shape[0]):\n",
    "                currents_per_neuron[label][pattern][neuron][time_step] = intensity_per_neuron[label][pattern][neuron]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instanciar uma camada de neurônios e aplicar a corrente em cada um:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_layer = []\n",
    "for i in range(num_neurons):\n",
    "    neuron_layer.append(Izhikevich(neuron_type='RS'))\n",
    "\n",
    "spike_train = np.zeros((num_labels, num_patterns, num_neurons, timeline.shape[0]))\n",
    "spike_count = np.zeros((num_labels, num_patterns, num_neurons))\n",
    "neurons_pot = np.zeros((num_labels, num_patterns, num_neurons, timeline.shape[0]))\n",
    "\n",
    "for label in range(num_labels):\n",
    "    for pattern in range(num_patterns):\n",
    "        for neuron in range(num_neurons):\n",
    "            I = currents_per_neuron[label][pattern][neuron]\n",
    "            sc = neuron_layer[neuron].spikeResponse(I, dt, spike_train[label][pattern][neuron], neurons_pot[label][pattern][neuron])\n",
    "            spike_count[label][pattern][neuron] = sc\n",
    "            neuron_layer[neuron].setNeuronBaseProperties()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização dos resultados: Contagem de spikes, Spike Train, Potencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spkViz = SpikeViz(original_image=ipp.patlab_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_neurons == 1):\n",
    "    spkViz.printSpikeViz(spike_obj=spike_count, \n",
    "                     x_label=\"Neurônio\",\n",
    "                     y_label=\"Quantidade de Spikes\",\n",
    "                     by_neuron=True, neuron_idx=0)\n",
    "                    \n",
    "else:\n",
    "    spkViz.printSpikeViz(spike_obj=spike_count, \n",
    "                        x_label=\"Índice do Neurônio\",\n",
    "                        y_label=\"Quantidade de Spikes\",\n",
    "                        by_neuron=False )\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spkViz.printSpikeViz(spike_obj=spike_train, \n",
    "                     x_label=\"Tempo (passos)\",\n",
    "                     y_label=\"Estado do neurônio (1 = Spike)\",\n",
    "                     by_neuron= True,\n",
    "                     neuron_idx = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spkViz.printSpikeViz(spike_obj=neurons_pot, \n",
    "                     x_label=\"Tempo (passos)\",\n",
    "                     y_label=\"Potencial do neurônio (mV)\",\n",
    "                     by_neuron= True, \n",
    "                     neuron_idx = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicação dos spikes como entrada de uma MLP com neurônios Preceptron.\n",
    "## Será necessário juntar com os labels de cada dígito, assim como definir um spike train desejado para a rede neural.\n",
    "## Uma forma de validar seu desempenho é comparando o treinamento de cada caso de Rede Neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para treinar os spikes codificados, é necessário quebrar o formato da base de saída para apresentar apenas a partir dos padrões(x_train) e os valores esperados dos labels(y_train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_y_train = []\n",
    "for i in range(num_labels):\n",
    "    for j in range(num_patterns):\n",
    "        for k in range(num_neurons):\n",
    "            spikes_y_train.append(i)\n",
    "spikes_y_train = np.asarray(spikes_y_train)\n",
    "spikes_y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_x_train = []\n",
    "for i in range(num_labels):\n",
    "    for j in range(num_patterns):\n",
    "        for k in range(num_neurons):\n",
    "            spikes_x_train.append(spike_train[i][j][k])\n",
    "\n",
    "spikes_x_train = np.asarray(spikes_x_train)\n",
    "spikes_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_patterns = 50\n",
    "num_classes = 10\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.Input(shape=(spike_train.shape[3],)))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(spike_train.shape[0]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e43dd8bb75c62a6ecf1af3f36a5e1d06e418643f35b874ce51f57c1f90762855"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
